{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SMS Spam Detection NLP Pipeline Generative vs Discriminative + Sparse vs Dense\n",
        "\n",
        "**Stakeholder & scenario:**\n",
        "\n",
        "A telecom company wants to automatically detect spam SMS to protect customers from fraud and reduce support complaints. The model will classify incoming messages as spam or ham (legit), enabling warning/blocking systems."
      ],
      "metadata": {
        "id": "QHwaAZkn7qgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e8faTgk5F93r"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas numpy scikit-learn nltk gensim matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja1v6Tqm8dAx",
        "outputId": "fb4bd093-3758-4944-85d6-864088d20f2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df = pd.read_table(url, header=None, names=[\"label\", \"text\"])\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gAMnYhnv8nN9",
        "outputId": "41a1520b-5366-4c29-ca87-7ddf8ecf8e7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27cf592f-f6ef-4af7-8a71-9e17b88b2ccc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27cf592f-f6ef-4af7-8a71-9e17b88b2ccc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27cf592f-f6ef-4af7-8a71-9e17b88b2ccc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27cf592f-f6ef-4af7-8a71-9e17b88b2ccc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", df.shape)\n",
        "print(df[\"label\"].value_counts())\n",
        "print(\"\\nClass ratio (%):\")\n",
        "print(df[\"label\"].value_counts(normalize=True) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvfkn_mO8sBs",
        "outputId": "02c649df-c95d-4c3d-fda4-7b28d9bcd037"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (5572, 2)\n",
            "label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class ratio (%):\n",
            "label\n",
            "ham     86.593683\n",
            "spam    13.406317\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cls in [\"ham\", \"spam\"]:\n",
        "    print(f\"\\n--- {cls.upper()} examples ---\")\n",
        "    for t in df[df[\"label\"] == cls][\"text\"].head(5).tolist():\n",
        "        print(\"-\", t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otTSBRYO82wr",
        "outputId": "fcf29332-172c-47d2-c037-63638463a0db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- HAM examples ---\n",
            "- Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "- Ok lar... Joking wif u oni...\n",
            "- U dun say so early hor... U c already then say...\n",
            "- Nah I don't think he goes to usf, he lives around here though\n",
            "- Even my brother is not like to speak with me. They treat me like aids patent.\n",
            "\n",
            "--- SPAM examples ---\n",
            "- Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "- FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
            "- WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
            "- Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
            "- SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"char_len\"] = df[\"text\"].str.len()\n",
        "df[\"word_len\"] = df[\"text\"].str.split().apply(len)\n",
        "\n",
        "df.groupby(\"label\")[[\"char_len\",\"word_len\"]].mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "TfhT7Yv79CCD",
        "outputId": "d4584e48-e9e0-44ce-9be0-a93e7991c274"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         char_len   word_len\n",
              "label                       \n",
              "ham     71.482487  14.310259\n",
              "spam   138.670683  23.911647"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c6374d7-2dc9-47a6-8488-bd839bdf3e06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>char_len</th>\n",
              "      <th>word_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>71.482487</td>\n",
              "      <td>14.310259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>138.670683</td>\n",
              "      <td>23.911647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c6374d7-2dc9-47a6-8488-bd839bdf3e06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c6374d7-2dc9-47a6-8488-bd839bdf3e06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c6374d7-2dc9-47a6-8488-bd839bdf3e06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"char_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.50922878405129,\n        \"min\": 71.48248704663213,\n        \"max\": 138.6706827309237,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          138.6706827309237,\n          71.48248704663213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.789206223476202,\n        \"min\": 14.310259067357514,\n        \"max\": 23.91164658634538,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          23.91164658634538,\n          14.310259067357514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Val/Test Split"
      ],
      "metadata": {
        "id": "y7_v2eQy93UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels and split\n",
        "\n",
        "df[\"y\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "X = df[\"text\"].values\n",
        "y = df[\"y\"].values\n",
        "\n",
        "# First split: train (70%) vs temp (30%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: val (10%) vs test (20%) from temp (30%)\n",
        "# val proportion of temp = 10/30 = 1/3\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=2/3, random_state=SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(X_train), \"Val:\", len(X_val), \"Test:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnFHE-Kf9932",
        "outputId": "2e0f8ac3-6efb-4562-b256-84430ae2ab7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 3900 Val: 557 Test: 1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "rm-R2Lyj-LtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Preprocessor\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_tokens(text: str):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "5RRH7Lgk-Ta4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = X_train[0]\n",
        "print(\"Original:\\n\", sample)\n",
        "print(\"\\nTokens:\\n\", preprocess_tokens(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZuB7EQg-hBO",
        "outputId": "880ae027-87d2-4ad9-a035-bd38cd0fd8d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            " Goal! Arsenal 4 (Henry, 7 v Liverpool 2 Henry scores with a simple shot from 6 yards from a pass by Bergkamp to give Arsenal a 2 goal margin after 78 mins.\n",
            "\n",
            "Tokens:\n",
            " ['goal', 'arsenal', 'henry', 'v', 'liverpool', 'henry', 'score', 'simple', 'shot', 'yard', 'pas', 'bergkamp', 'give', 'arsenal', 'goal', 'margin', 'min']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "dy5GdvGv_Ftf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BoW + Naive Bayes (Generative Model)\n",
        "\n",
        "bow_nb = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(\n",
        "        tokenizer=preprocess_tokens,\n",
        "        ngram_range=(1,1)\n",
        "    )),\n",
        "    (\"classifier\", MultinomialNB())\n",
        "])\n",
        "\n",
        "bow_nb.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = bow_nb.predict(X_val)\n",
        "\n",
        "print(\"BoW + Naive Bayes (Validation)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO4qyrFq_KbJ",
        "outputId": "c22f2ad0-aeb8-4827-c3a0-c9b4e385dbdc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW + Naive Bayes (Validation)\n",
            "Accuracy: 0.9820466786355476\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       482\n",
            "        spam       0.99      0.88      0.93        75\n",
            "\n",
            "    accuracy                           0.98       557\n",
            "   macro avg       0.98      0.94      0.96       557\n",
            "weighted avg       0.98      0.98      0.98       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Naive Bayes is a generative classifier that models word distributions within each class. It performs well on count-based sparse features such as Bag-of-Words."
      ],
      "metadata": {
        "id": "GYu4ehm8_YNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BoW + Logistic Regression (Discriminative)\n",
        "\n",
        "bow_lr = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(\n",
        "        tokenizer=preprocess_tokens,\n",
        "        ngram_range=(1,1)\n",
        "    )),\n",
        "    (\"classifier\", LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        random_state=SEED\n",
        "    ))\n",
        "])\n",
        "\n",
        "bow_lr.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = bow_lr.predict(X_val)\n",
        "\n",
        "print(\"BoW + Logistic Regression (Validation)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkBP-vf9_cVE",
        "outputId": "80a81ffa-d1a7-440f-f9ae-051ab4c5f82b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW + Logistic Regression (Validation)\n",
            "Accuracy: 0.9748653500897666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.99       482\n",
            "        spam       1.00      0.81      0.90        75\n",
            "\n",
            "    accuracy                           0.97       557\n",
            "   macro avg       0.99      0.91      0.94       557\n",
            "weighted avg       0.98      0.97      0.97       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF + Naive Bayes\n",
        "\n",
        "tfidf_nb = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(\n",
        "        tokenizer=preprocess_tokens,\n",
        "        ngram_range=(1,2)\n",
        "    )),\n",
        "    (\"classifier\", MultinomialNB())\n",
        "])\n",
        "\n",
        "tfidf_nb.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = tfidf_nb.predict(X_val)\n",
        "\n",
        "print(\"TF-IDF (1,2) + Naive Bayes (Validation)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNU4IqsH_n6p",
        "outputId": "8441d9fc-5d95-45c5-a436-0b97c8d7aec8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF (1,2) + Naive Bayes (Validation)\n",
            "Accuracy: 0.9533213644524237\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      1.00      0.97       482\n",
            "        spam       1.00      0.65      0.79        75\n",
            "\n",
            "    accuracy                           0.95       557\n",
            "   macro avg       0.97      0.83      0.88       557\n",
            "weighted avg       0.96      0.95      0.95       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF + Linear SVM (Strong baseline)\n",
        "\n",
        "tfidf_svm = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(\n",
        "        tokenizer=preprocess_tokens,\n",
        "        ngram_range=(1,2)\n",
        "    )),\n",
        "    (\"classifier\", LinearSVC(random_state=SEED))\n",
        "])\n",
        "\n",
        "tfidf_svm.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = tfidf_svm.predict(X_val)\n",
        "\n",
        "print(\"TF-IDF (1,2) + Linear SVM (Validation)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU72kvjf_uyd",
        "outputId": "9dc5f8b8-e5ac-4e47-80b3-6335c14bcb6d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF (1,2) + Linear SVM (Validation)\n",
            "Accuracy: 0.9856373429084381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       482\n",
            "        spam       1.00      0.89      0.94        75\n",
            "\n",
            "    accuracy                           0.99       557\n",
            "   macro avg       0.99      0.95      0.97       557\n",
            "weighted avg       0.99      0.99      0.99       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tokenized data\n",
        "\n",
        "train_tokens = [preprocess_tokens(t) for t in X_train]\n",
        "val_tokens   = [preprocess_tokens(t) for t in X_val]\n",
        "test_tokens  = [preprocess_tokens(t) for t in X_test]\n"
      ],
      "metadata": {
        "id": "7VmX-CmzAHXu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec (Skip-gram)\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=train_tokens,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=2,\n",
        "    sg=1,     # Skip-gram\n",
        "    seed=SEED\n",
        ")\n"
      ],
      "metadata": {
        "id": "nSe5xhvOAOP6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert messages → vectors\n",
        "\n",
        "def document_vector(tokens, model):\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "X_train_w2v = np.vstack([document_vector(t, w2v_model) for t in train_tokens])\n",
        "X_val_w2v   = np.vstack([document_vector(t, w2v_model) for t in val_tokens])\n",
        "X_test_w2v  = np.vstack([document_vector(t, w2v_model) for t in test_tokens])\n"
      ],
      "metadata": {
        "id": "ZgYzXYMTAUzz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec + Logistic Regression\n",
        "\n",
        "w2v_lr = LogisticRegression(max_iter=2000, random_state=SEED)\n",
        "w2v_lr.fit(X_train_w2v, y_train)\n",
        "\n",
        "y_val_pred = w2v_lr.predict(X_val_w2v)\n",
        "\n",
        "print(\"Word2Vec + Logistic Regression (Validation)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X97Da-0uAbf9",
        "outputId": "f9a9f19d-937d-4e46-9cbe-cfa5815fb7fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec + Logistic Regression (Validation)\n",
            "Accuracy: 0.9587073608617595\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.99      0.98       482\n",
            "        spam       0.92      0.76      0.83        75\n",
            "\n",
            "    accuracy                           0.96       557\n",
            "   macro avg       0.94      0.87      0.90       557\n",
            "weighted avg       0.96      0.96      0.96       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec + Linear SVM\n",
        "\n",
        "w2v_svm = LinearSVC(random_state=SEED)\n",
        "w2v_svm.fit(X_train_w2v, y_train)\n",
        "\n",
        "y_val_pred = w2v_svm.predict(X_val_w2v)\n",
        "\n",
        "print(\"Word2Vec + Linear SVM (Validation)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWJtWWE1Aio1",
        "outputId": "13283267-5215-437d-cbf7-e98ecea5b520"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec + Linear SVM (Validation)\n",
            "Accuracy: 0.9658886894075404\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98       482\n",
            "        spam       0.94      0.80      0.86        75\n",
            "\n",
            "    accuracy                           0.97       557\n",
            "   macro avg       0.95      0.90      0.92       557\n",
            "weighted avg       0.97      0.97      0.96       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Evaluation on TEST"
      ],
      "metadata": {
        "id": "LLy0_6ewAywT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Help functions\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"binary\", zero_division=0\n",
        "    )\n",
        "    return acc, p, r, f1\n"
      ],
      "metadata": {
        "id": "n5rpYEgnBvb8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# ---- Sparse pipelines ----\n",
        "sparse_models = {\n",
        "    \"BoW + Naive Bayes\": bow_nb,\n",
        "    \"BoW + Logistic Regression\": bow_lr,\n",
        "    \"TF-IDF(1,2) + Naive Bayes\": tfidf_nb,\n",
        "    \"TF-IDF(1,2) + Linear SVM\": tfidf_svm,\n",
        "}\n",
        "\n",
        "for name, model in sparse_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc, p, r, f1 = get_metrics(y_test, y_pred)\n",
        "    results.append([name, acc, p, r, f1])\n",
        "\n",
        "# ---- Dense models (Word2Vec vectors) ----\n",
        "y_pred = w2v_lr.predict(X_test_w2v)\n",
        "results.append([\"Word2Vec(avg) + Logistic Regression\", *get_metrics(y_test, y_pred)])\n",
        "\n",
        "y_pred = w2v_svm.predict(X_test_w2v)\n",
        "results.append([\"Word2Vec(avg) + Linear SVM\", *get_metrics(y_test, y_pred)])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "results_df = results_df.sort_values(\"F1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "rlMDFjehB4Ix",
        "outputId": "2395817a-a6d5-438d-f6ef-43390a66e05f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Model  Accuracy  Precision    Recall  \\\n",
              "0             TF-IDF(1,2) + Linear SVM  0.983857   0.958042  0.919463   \n",
              "1            BoW + Logistic Regression  0.983857   0.992481  0.885906   \n",
              "2                    BoW + Naive Bayes  0.982960   0.939189  0.932886   \n",
              "3            TF-IDF(1,2) + Naive Bayes  0.967713   1.000000  0.758389   \n",
              "4           Word2Vec(avg) + Linear SVM  0.950673   0.879032  0.731544   \n",
              "5  Word2Vec(avg) + Logistic Regression  0.939910   0.866071  0.651007   \n",
              "\n",
              "         F1  \n",
              "0  0.938356  \n",
              "1  0.936170  \n",
              "2  0.936027  \n",
              "3  0.862595  \n",
              "4  0.798535  \n",
              "5  0.743295  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a640cd1-a2f0-4f10-9a0a-1af6a0ea7108\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TF-IDF(1,2) + Linear SVM</td>\n",
              "      <td>0.983857</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.919463</td>\n",
              "      <td>0.938356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BoW + Logistic Regression</td>\n",
              "      <td>0.983857</td>\n",
              "      <td>0.992481</td>\n",
              "      <td>0.885906</td>\n",
              "      <td>0.936170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BoW + Naive Bayes</td>\n",
              "      <td>0.982960</td>\n",
              "      <td>0.939189</td>\n",
              "      <td>0.932886</td>\n",
              "      <td>0.936027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TF-IDF(1,2) + Naive Bayes</td>\n",
              "      <td>0.967713</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.758389</td>\n",
              "      <td>0.862595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Word2Vec(avg) + Linear SVM</td>\n",
              "      <td>0.950673</td>\n",
              "      <td>0.879032</td>\n",
              "      <td>0.731544</td>\n",
              "      <td>0.798535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Word2Vec(avg) + Logistic Regression</td>\n",
              "      <td>0.939910</td>\n",
              "      <td>0.866071</td>\n",
              "      <td>0.651007</td>\n",
              "      <td>0.743295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a640cd1-a2f0-4f10-9a0a-1af6a0ea7108')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a640cd1-a2f0-4f10-9a0a-1af6a0ea7108 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a640cd1-a2f0-4f10-9a0a-1af6a0ea7108');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_06352ded-abbc-43ee-8cee-bd83b0695b48\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_06352ded-abbc-43ee-8cee-bd83b0695b48 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"TF-IDF(1,2) + Linear SVM\",\n          \"BoW + Logistic Regression\",\n          \"Word2Vec(avg) + Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01905697700526978,\n        \"min\": 0.9399103139013453,\n        \"max\": 0.9838565022421525,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9829596412556054,\n          0.9399103139013453,\n          0.967713004484305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05631778875484253,\n        \"min\": 0.8660714285714286,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.958041958041958,\n          0.9924812030075187,\n          0.8660714285714286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1156558443918707,\n        \"min\": 0.6510067114093959,\n        \"max\": 0.9328859060402684,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9194630872483222,\n          0.8859060402684564,\n          0.6510067114093959\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08321378618207319,\n        \"min\": 0.7432950191570882,\n        \"max\": 0.9383561643835616,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9383561643835616,\n          0.9361702127659575,\n          0.7432950191570882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = results_df.loc[0, \"Model\"]\n",
        "print(\"Best model based on F1:\", best_model_name)\n",
        "\n",
        "# Re-create y_pred for best model\n",
        "if best_model_name in sparse_models:\n",
        "    best_model = sparse_models[best_model_name]\n",
        "    y_pred_best = best_model.predict(X_test)\n",
        "else:\n",
        "    # Word2Vec cases\n",
        "    if \"Logistic\" in best_model_name:\n",
        "        y_pred_best = w2v_lr.predict(X_test_w2v)\n",
        "    else:\n",
        "        y_pred_best = w2v_svm.predict(X_test_w2v)\n",
        "\n",
        "print(\"\\nDetailed classification report (TEST):\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=[\"ham\", \"spam\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRKayveJB7zC",
        "outputId": "00a4274f-dfbe-439e-fead-eb588c87ebd7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model based on F1: TF-IDF(1,2) + Linear SVM\n",
            "\n",
            "Detailed classification report (TEST):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       966\n",
            "        spam       0.96      0.92      0.94       149\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.97      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis & Discussion\n",
        "\n",
        "Generative vs Discriminative Models\n",
        "\n",
        "In this project, both generative and discriminative classifiers were evaluated for SMS spam detection.\n",
        "\n",
        "Multinomial Naive Bayes is a generative model, as it learns the probability distribution of words within each class (spam or ham) and applies Bayes’ theorem to make predictions. This approach is computationally efficient and performs well with count-based features.\n",
        "\n",
        "Linear SVM, on the other hand, is a discriminative model. It directly learns a decision boundary that best separates spam and ham messages in the feature space without modeling how the text itself is generated.\n",
        "\n",
        "Observation:\n",
        "The TF-IDF (1,2) + Linear SVM model achieved the highest F1-score on the test set. This suggests that discriminative models were better able to exploit the informative weighted features produced by TF-IDF, especially when bigrams were included. While Naive Bayes performed competitively, it was outperformed by Linear SVM in terms of overall classification balance.\n",
        "\n",
        "Sparse vs Dense Representations\n",
        "\n",
        "Two types of feature representations were compared: sparse vectors (Bag-of-Words and TF-IDF) and dense embeddings (Word2Vec).\n",
        "\n",
        "Sparse representations treat each word or phrase as an independent feature. TF-IDF improves upon Bag-of-Words by reducing the influence of very frequent but less informative words while emphasizing rare and discriminative terms.\n",
        "\n",
        "Dense Word2Vec embeddings capture semantic similarity between words by learning distributed representations based on context. Document-level vectors were obtained by averaging word embeddings.\n",
        "\n",
        "Observation:\n",
        "The sparse TF-IDF representation outperformed the Word2Vec-based models. This is likely because SMS spam detection relies heavily on specific keywords and short phrases (e.g., “call now”, “free entry”, “win prize”) that TF-IDF captures effectively. Averaging Word2Vec embeddings may dilute such signals, especially in short text messages.\n",
        "\n",
        "Effect of N-grams\n",
        "\n",
        "Including bigrams (1,2-grams) in the TF-IDF representation contributed to improved performance. Bigrams allow the model to capture short but meaningful phrases commonly found in spam messages, such as “call now” or “limited offer”.\n",
        "\n",
        "However, using higher-order n-grams also increases the feature space size, leading to higher memory usage and longer training times. In this case, the performance gains from bigrams justified the additional complexity.\n",
        "\n",
        "Speed, Memory, and Explainability Trade-offs\n",
        "\n",
        "Naive Bayes was the fastest and most memory-efficient model and offered high interpretability through class-conditional word probabilities.\n",
        "\n",
        "TF-IDF + Linear SVM required more computational resources but delivered the best predictive performance.\n",
        "\n",
        "Word2Vec-based models required additional training time and were less interpretable, as individual dimensions of dense embeddings do not correspond to human-readable features.\n",
        "\n",
        "Overall, TF-IDF combined with Linear SVM provided the best balance between performance and practicality for this real-world SMS spam detection task."
      ],
      "metadata": {
        "id": "76lnFLtYCs1I"
      }
    }
  ]
}